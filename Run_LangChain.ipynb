{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465f3151-e6ea-4004-aaf4-c7b591717c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec rag-gpu in /root/.local/share/jupyter/kernels/rag-gpu\n"
     ]
    }
   ],
   "source": [
    "!python -m ipykernel install --user --name rag-gpu --display-name \"Python (rag-gpu)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7e5af0-b259-4f8b-acc5-73816ab81cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirement.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2bb0bf-2aa0-4e92-bd5e-d64fa79e228f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading 3-4-million-spotify-google-store-reviews.zip to /workspace\n",
      " 98%|███████████████████████████████████████▍| 257M/261M [00:09<00:00, 31.8MB/s]\n",
      "100%|████████████████████████████████████████| 261M/261M [00:09<00:00, 27.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "!kaggle datasets download 'bwandowando/3-4-million-spotify-google-store-reviews'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e1fb1c8-3832-4163-9003-fac36859cebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘dataset’: File exists\n",
      "Archive:  3-4-million-spotify-google-store-reviews.zip\n",
      "  inflating: dataset/SPOTIFY_REVIEWS.csv  \n"
     ]
    }
   ],
   "source": [
    "!mkdir dataset\n",
    "!apt-get update\n",
    "!apt-install unzip\n",
    "!unzip 3-4-million-spotify-google-store-reviews.zip -d dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a9f8c37-2f69-45fc-957d-0b352594a71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from preprocess import PreprocessDataFrame\n",
    "from rag import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0aafe31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess the dataset\n",
    "df = PreprocessDataFrame(\"dataset/SPOTIFY_REVIEWS.csv\").cleaningDataFrame()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd068640-2d50-471a-bbfa-fbdcc4470d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save preprocess dataframe into new file\n",
    "temp = df[[\"review_id\",\"clean_review_text\", \"pseudo_author_id\"]].reset_index(drop=True)\n",
    "temp.to_csv(\"dataset/clean_spotify_review_id_text.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00030a53-082c-4a92-a257-3f12b2f987c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='i enjoy the awesome ui of this app and it has all the music one can ask for.', metadata={'review_id': 'bfa8876b-470e-4640-83a7-77427f7f37e8', 'pseudo_author_id': '234382942865437071667'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the clean dataframe into docs format\n",
    "docs = load_dataset(\"dataset/clean_spotify_review_id_text_1000.csv\", \"review_id\", type_file=\"dataframe\",\n",
    "                   chunk_size=300, chunk_overlap=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed0f8a6d-649c-4577-a8dd-4561a2b5ecae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "#define embeddings\n",
    "# thenlper/gte-large sentence-transformers/all-mpnet-base-v2\n",
    "modelPath = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "model_kwargs = {'device': 'cuda'}\n",
    "encode_kwargs = {'normalize_embeddings': True}\n",
    "\n",
    "embeddings = define_embedding(modelPath, model_kwargs, encode_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "995c7cc9-9081-4049-86dc-ea0e15c5c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = load_faiss_db(\"faiss_index_all-mpnet-base-v2_cs500_co50_1000\", embeddings=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793ae3d9-367f-419e-b6aa-14a8ada97c9a",
   "metadata": {},
   "source": [
    "## LLaMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a293220-dac1-4a7c-b8a6-a67809b9f91e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1858407ae84761bb71cd2039ce0d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at namespace-Pt/activation-beacon-llama2-7b-chat were not used when initializing LlamaForCausalLM: ['model.beacon_embed_tokens.weight', 'model.layers.0.self_attn.beacon_k_proj.weight', 'model.layers.0.self_attn.beacon_o_proj.weight', 'model.layers.0.self_attn.beacon_q_proj.weight', 'model.layers.0.self_attn.beacon_v_proj.weight', 'model.layers.1.self_attn.beacon_k_proj.weight', 'model.layers.1.self_attn.beacon_o_proj.weight', 'model.layers.1.self_attn.beacon_q_proj.weight', 'model.layers.1.self_attn.beacon_v_proj.weight', 'model.layers.10.self_attn.beacon_k_proj.weight', 'model.layers.10.self_attn.beacon_o_proj.weight', 'model.layers.10.self_attn.beacon_q_proj.weight', 'model.layers.10.self_attn.beacon_v_proj.weight', 'model.layers.11.self_attn.beacon_k_proj.weight', 'model.layers.11.self_attn.beacon_o_proj.weight', 'model.layers.11.self_attn.beacon_q_proj.weight', 'model.layers.11.self_attn.beacon_v_proj.weight', 'model.layers.12.self_attn.beacon_k_proj.weight', 'model.layers.12.self_attn.beacon_o_proj.weight', 'model.layers.12.self_attn.beacon_q_proj.weight', 'model.layers.12.self_attn.beacon_v_proj.weight', 'model.layers.13.self_attn.beacon_k_proj.weight', 'model.layers.13.self_attn.beacon_o_proj.weight', 'model.layers.13.self_attn.beacon_q_proj.weight', 'model.layers.13.self_attn.beacon_v_proj.weight', 'model.layers.14.self_attn.beacon_k_proj.weight', 'model.layers.14.self_attn.beacon_o_proj.weight', 'model.layers.14.self_attn.beacon_q_proj.weight', 'model.layers.14.self_attn.beacon_v_proj.weight', 'model.layers.15.self_attn.beacon_k_proj.weight', 'model.layers.15.self_attn.beacon_o_proj.weight', 'model.layers.15.self_attn.beacon_q_proj.weight', 'model.layers.15.self_attn.beacon_v_proj.weight', 'model.layers.16.self_attn.beacon_k_proj.weight', 'model.layers.16.self_attn.beacon_o_proj.weight', 'model.layers.16.self_attn.beacon_q_proj.weight', 'model.layers.16.self_attn.beacon_v_proj.weight', 'model.layers.17.self_attn.beacon_k_proj.weight', 'model.layers.17.self_attn.beacon_o_proj.weight', 'model.layers.17.self_attn.beacon_q_proj.weight', 'model.layers.17.self_attn.beacon_v_proj.weight', 'model.layers.18.self_attn.beacon_k_proj.weight', 'model.layers.18.self_attn.beacon_o_proj.weight', 'model.layers.18.self_attn.beacon_q_proj.weight', 'model.layers.18.self_attn.beacon_v_proj.weight', 'model.layers.19.self_attn.beacon_k_proj.weight', 'model.layers.19.self_attn.beacon_o_proj.weight', 'model.layers.19.self_attn.beacon_q_proj.weight', 'model.layers.19.self_attn.beacon_v_proj.weight', 'model.layers.2.self_attn.beacon_k_proj.weight', 'model.layers.2.self_attn.beacon_o_proj.weight', 'model.layers.2.self_attn.beacon_q_proj.weight', 'model.layers.2.self_attn.beacon_v_proj.weight', 'model.layers.20.self_attn.beacon_k_proj.weight', 'model.layers.20.self_attn.beacon_o_proj.weight', 'model.layers.20.self_attn.beacon_q_proj.weight', 'model.layers.20.self_attn.beacon_v_proj.weight', 'model.layers.21.self_attn.beacon_k_proj.weight', 'model.layers.21.self_attn.beacon_o_proj.weight', 'model.layers.21.self_attn.beacon_q_proj.weight', 'model.layers.21.self_attn.beacon_v_proj.weight', 'model.layers.22.self_attn.beacon_k_proj.weight', 'model.layers.22.self_attn.beacon_o_proj.weight', 'model.layers.22.self_attn.beacon_q_proj.weight', 'model.layers.22.self_attn.beacon_v_proj.weight', 'model.layers.23.self_attn.beacon_k_proj.weight', 'model.layers.23.self_attn.beacon_o_proj.weight', 'model.layers.23.self_attn.beacon_q_proj.weight', 'model.layers.23.self_attn.beacon_v_proj.weight', 'model.layers.24.self_attn.beacon_k_proj.weight', 'model.layers.24.self_attn.beacon_o_proj.weight', 'model.layers.24.self_attn.beacon_q_proj.weight', 'model.layers.24.self_attn.beacon_v_proj.weight', 'model.layers.25.self_attn.beacon_k_proj.weight', 'model.layers.25.self_attn.beacon_o_proj.weight', 'model.layers.25.self_attn.beacon_q_proj.weight', 'model.layers.25.self_attn.beacon_v_proj.weight', 'model.layers.26.self_attn.beacon_k_proj.weight', 'model.layers.26.self_attn.beacon_o_proj.weight', 'model.layers.26.self_attn.beacon_q_proj.weight', 'model.layers.26.self_attn.beacon_v_proj.weight', 'model.layers.27.self_attn.beacon_k_proj.weight', 'model.layers.27.self_attn.beacon_o_proj.weight', 'model.layers.27.self_attn.beacon_q_proj.weight', 'model.layers.27.self_attn.beacon_v_proj.weight', 'model.layers.28.self_attn.beacon_k_proj.weight', 'model.layers.28.self_attn.beacon_o_proj.weight', 'model.layers.28.self_attn.beacon_q_proj.weight', 'model.layers.28.self_attn.beacon_v_proj.weight', 'model.layers.29.self_attn.beacon_k_proj.weight', 'model.layers.29.self_attn.beacon_o_proj.weight', 'model.layers.29.self_attn.beacon_q_proj.weight', 'model.layers.29.self_attn.beacon_v_proj.weight', 'model.layers.3.self_attn.beacon_k_proj.weight', 'model.layers.3.self_attn.beacon_o_proj.weight', 'model.layers.3.self_attn.beacon_q_proj.weight', 'model.layers.3.self_attn.beacon_v_proj.weight', 'model.layers.30.self_attn.beacon_k_proj.weight', 'model.layers.30.self_attn.beacon_o_proj.weight', 'model.layers.30.self_attn.beacon_q_proj.weight', 'model.layers.30.self_attn.beacon_v_proj.weight', 'model.layers.31.self_attn.beacon_k_proj.weight', 'model.layers.31.self_attn.beacon_o_proj.weight', 'model.layers.31.self_attn.beacon_q_proj.weight', 'model.layers.31.self_attn.beacon_v_proj.weight', 'model.layers.4.self_attn.beacon_k_proj.weight', 'model.layers.4.self_attn.beacon_o_proj.weight', 'model.layers.4.self_attn.beacon_q_proj.weight', 'model.layers.4.self_attn.beacon_v_proj.weight', 'model.layers.5.self_attn.beacon_k_proj.weight', 'model.layers.5.self_attn.beacon_o_proj.weight', 'model.layers.5.self_attn.beacon_q_proj.weight', 'model.layers.5.self_attn.beacon_v_proj.weight', 'model.layers.6.self_attn.beacon_k_proj.weight', 'model.layers.6.self_attn.beacon_o_proj.weight', 'model.layers.6.self_attn.beacon_q_proj.weight', 'model.layers.6.self_attn.beacon_v_proj.weight', 'model.layers.7.self_attn.beacon_k_proj.weight', 'model.layers.7.self_attn.beacon_o_proj.weight', 'model.layers.7.self_attn.beacon_q_proj.weight', 'model.layers.7.self_attn.beacon_v_proj.weight', 'model.layers.8.self_attn.beacon_k_proj.weight', 'model.layers.8.self_attn.beacon_o_proj.weight', 'model.layers.8.self_attn.beacon_q_proj.weight', 'model.layers.8.self_attn.beacon_v_proj.weight', 'model.layers.9.self_attn.beacon_k_proj.weight', 'model.layers.9.self_attn.beacon_o_proj.weight', 'model.layers.9.self_attn.beacon_q_proj.weight', 'model.layers.9.self_attn.beacon_v_proj.weight']\n",
      "- This IS expected if you are initializing LlamaForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing LlamaForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# clibrain/Llama-2-7b-ft-instruct-es-gptq-4bi TheBloke/Llama-2-7B-GPTQ togethercomputer/LLaMA-2-7B-32K \n",
    "\n",
    "model_name = 'namespace-Pt/activation-beacon-llama2-7b-chat'\n",
    "model, tokenizer = define_llm(model_name, True)\n",
    "llm_chain = create_response_chain(model, tokenizer, 256, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3150c8e-316a-4e13-82ed-5d6ec7ef36d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I can only provide answers based on the information provided in the context. However, I must inform you that making assumptions or generalizations about users' thoughts without concrete evidence may not be entirely accurate. The reviews and comments provided suggest that some users find Spotify to be better than Pandora, while others have mixed opinions.\n",
      "\n",
      "It's important to recognize that user preferences and experiences can vary greatly, and it's not appropriate to make sweeping statements about either platform without considering individual perspectives. Both Spotify and Pandora offer unique features and capabilities, and the best choice for a particular user depends on their specific needs and preferences.\n",
      "\n",
      "In summary, while some users may find Spotify to be better than Pandora, it's essential to acknowledge that individual opinions and experiences can differ significantly. It's crucial to approach these types of questions with nuance and sensitivity towards the diversity of user perspectives.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the specific features or aspects that users appreciate the most in our application?\"\n",
    "answer, relevant_docs = answer_with_rag(question, llm_chain, db, k_retrieve=10)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c37dafd-277d-492e-a1c4-0c7d84ddffba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"so far it's way better than pandora.\", 'much better than pandora. a lot of variety and i feel like the developers care about bringing their audience a musical experience', \"so far i'm really enjoying this app far better than pandora.\", 'have had the app for a few weeks much better than pandora', 'so far i have liked this app more than pandora', 'i recomend this app to music lovers better than pandora.', \"overall it's better than pandora but it could be improved.\", \"it's an amazing app.. idk why people don't use this instead of pandora but this is an overall good app\", 'i will think this app is better than pandora', 'the app works great and seems to have much more versatility than pandora']\n"
     ]
    }
   ],
   "source": [
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6bb9a0-baf2-4964-9cd0-04a53f8091e5",
   "metadata": {},
   "source": [
    "## Zephyr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f63d321-7654-4cb0-a12b-1014e28100c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d10ba8503705480ba219af8ca7152093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49d7223564642f19c9a34fe62676695",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc9abe823f8432aa74423d94e828b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05301b2ec3024592bcda914a4717cc0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7e6eb68b7d944258ffd7b4429c1df47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43ca94a3feff4ead800a067829ba5b70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/168 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88902a6fcd7047a0afbfd90301481fda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2575d3cd57fd4738b8b82b5a505429d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68688b2f7e494a7ebebc4bf606861098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00008.safetensors:   0%|          | 0.00/1.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4ed31be992e4f75b5422a72061a80b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "042c3dc9904b4bcea1202ec3f47f0aa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39140f96805f4edebef2cd50f1d40566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92d8fefc2650404681558535eaf5e514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5519edf2c9a140c58b9b7201727303b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00008.safetensors:   0%|          | 0.00/1.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed85ca98e9d34986862618d61235e29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00008.safetensors:   0%|          | 0.00/1.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d43c0db18833470aa88617cb12f5d47f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00008.safetensors:   0%|          | 0.00/816M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f422f3a7ad04f6f86697e8675af106f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c4e4d8f2d442a2a467864e82840a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/111 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'HuggingFaceH4/zephyr-7b-beta'\n",
    "model, tokenizer = define_llm(model_name, True)\n",
    "llm_chain = create_response_chain(model, tokenizer, 256, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a3d8986-cce4-4635-9ee7-ffbcf6fe3b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ### [ASS]\n",
      "    Based on the context provided, it can be inferred that users are most likely to compare our music streaming application (Spotify) with other popular music streaming platforms such as Apple Music, Tidal, and Amazon Music. Keywords like \"comparing other music app competitors\", \"preferred streaming music app\", \"best music platform\", and \"best music service\" suggest that users are actively seeking out alternatives to Spotify and may be considering these other platforms as well. However, the overwhelmingly positive sentiment towards Spotify in the reviews suggests that users are generally satisfied with the platform and may not feel a strong need to switch to another service. Nonetheless, it is still important for us to remain competitive and continue improving our offering to retain our users' loyalty.\n"
     ]
    }
   ],
   "source": [
    "question = \"In comparison to our application, which music streaming platform are users most likely to compare ours with?\"\n",
    "answer, relevant_docs = answer_with_rag(question, llm_chain, db, k_retrieve=10)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63597507-b771-497e-b150-1c23e46c5652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesome comparing other music app competitors', 'preferred streaming music app', 'my preferred online streaming music app', 'best music platform.', 'best music platform', 'best music platform', 'my preferred platform to stream all my favorite music', 'best streaming music platform', 'best music service.. best app and user experience across different devices and different operating systems', 'best music streaming app no comparison to the plethora of music content']\n"
     ]
    }
   ],
   "source": [
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623ee641-f0d9-47b4-bb9e-ee6a0fd54458",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Falcon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a42b1ea8-4189-473a-a6f5-fa012deb1c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f0f6a7fcac34e2596882b2331f7ed73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/660 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f8cd3dd766c4a088f3d4ab43bd0d1d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/445 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3099c35a6dc4282b02217c2921bfe60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcba9afc9ea34c04adc2950d285ed60d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b6a85a022d047fdbc31224c6452ccd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85495da8bf6a462d86de5a68b7811f98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/99.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9480bc403fe4a9cbfd828e53167fb7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.62G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf0de573af046f0a4e0550c93f42689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/89.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'ericzzz/falcon-rw-1b-instruct-openorca'\n",
    "model, tokenizer = define_llm(model_name, True)\n",
    "llm_chain = create_response_chain(model, tokenizer, 256, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7130e968-22b4-4278-8eee-84bb881a9f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The answer provided here is Apple Music Streaming Platform (Spotify).\n"
     ]
    }
   ],
   "source": [
    "question = \"In comparison to our application, which music streaming platform are users most likely to compare ours with?\"\n",
    "answer, relevant_docs = answer_with_rag(question, llm_chain, db, k_retrieve=30)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bee902d0-f0f2-4d57-844d-0710def3a8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesome comparing other music app competitors', 'preferred streaming music app', 'my preferred online streaming music app', 'best music platform.', 'best music platform', 'best music platform', 'my preferred platform to stream all my favorite music', 'best streaming music platform', 'best music service.. best app and user experience across different devices and different operating systems', 'best music streaming app no comparison to the plethora of music content', 'best music app better than others', 'best platform for streaming music. period', 'best music streaming platform', 'best music streaming platform', 'the best music platform', 'the best music platform', 'best music app no comparison with others', 'best platform for streaming music', 'greatest music streaming application with the largest catalogue of music.', 'best music streaming platform in the market', 'best music stream platform.', 'best music platform today', 'best streaming platform for music', 'best music app more music than others', 'best music streaming platform of all time', 'spotify to me is the best music streaming platform', 'best music streaming app we have found', 'i gave each major music streaming service a 2 month test run each. spotify came out on top for me. googles offering was in 2nd.. soundcloud had a lot of unique stuff i cant find anywhere else..and apple music was so frustratingly terrible.. i honestly went into my test thinking apples would have been the best. easily the worst.', 'better music app than others', 'best app streaming music']\n"
     ]
    }
   ],
   "source": [
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca12699-fa8d-4cac-95af-e490804c2986",
   "metadata": {},
   "source": [
    "## Mistral "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5933331-c680-4791-af22-443957dab21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0618df4d4eda4d41958aedd58e8c3edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f412c129b3a4afbb4b3e01bb054fbfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b736a0efd3a444919e3e52a966eb7266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39cb1a9241ae4e00b0a9e994bbc7c401",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "584dc10c323949ce80dabdd60eca302f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Your GPU supports bfloat16: accelerate training with bf16=True\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ecad6c839240dca981ed3956be7efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d69c88fb744483a2872c48d9eb4c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344e33480f5d4efeb33068734222a587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf1a60b3f0d42a780db674485a81e6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c5197c66fd24018bb65cdf741e2e8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec9629885c349519b7736bcc22ac3f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# mistralai/Mistral-7B-Instruct-v0.1 databricks/dolly-v2-3b\n",
    "model_name='mistralai/Mistral-7B-Instruct-v0.1'\n",
    "model, tokenizer = define_llm(model_name, True)\n",
    "llm_chain = create_response_chain(model, tokenizer, 256, temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c277441a-2f4d-4b75-b9b8-b108c30daa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_all = [\"In comparison to our application, which music streaming platform are users most likely to compare ours with?\",\n",
    "                 \"What are the specific features or aspects that users appreciate the most in our application?\",\n",
    "                 \"What are the primary reasons users express dissatisfaction with Spotify?\",\n",
    "                 \"Can you identify emerging trends or patterns in recent user reviews that may impact our product strategy?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd3c56de-56a5-4e0f-ac76-d2068fa37bcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What are the specific features or aspects that...</td>\n",
       "      <td>Users frequently praise the intuitive UI desig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In comparison to our application, which music ...</td>\n",
       "      <td>Users often draw comparisons with Pandora when...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What are the primary reasons users express dis...</td>\n",
       "      <td>Common concerns among dissatisfied users inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Can you identify emerging trends or patterns i...</td>\n",
       "      <td>Recent reviews highlight an increasing demand ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  What are the specific features or aspects that...   \n",
       "1  In comparison to our application, which music ...   \n",
       "2  What are the primary reasons users express dis...   \n",
       "3  Can you identify emerging trends or patterns i...   \n",
       "\n",
       "                                             answers  \n",
       "0  Users frequently praise the intuitive UI desig...  \n",
       "1  Users often draw comparisons with Pandora when...  \n",
       "2  Common concerns among dissatisfied users inclu...  \n",
       "3  Recent reviews highlight an increasing demand ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df = pd.read_csv(\"dataset/benchmark_dataset.csv\")\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a228a1a2-3d20-4702-a520-db7f93c114aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 25%|██▌       | 1/4 [00:08<00:26,  8.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the specific features or aspects that users appreciate the most in our application?\n",
      "\n",
      "    Based on the user reviews provided, some of the specific features or aspects that users appreciate the most in Spotify include:\n",
      "\n",
      "    - Ease of use and intuitive interface (multiple reviews)\n",
      "    - Wide variety of music and genres available (multiple reviews)\n",
      "    - Ability to discover new hits and recommendations (multiple reviews)\n",
      "    - Helpful and responsive customer service (multiple reviews)\n",
      "    - Social features such as helping others through the app (one review)\n",
      "    - Efficiency, convenience, and tonefriendliness in meeting user needs (two reviews)\n",
      "\n",
      "    These features contribute to overall satisfaction and enjoyment of the app, as noted by several users.\n",
      "{'bleu': 0.0, 'precisions': [0.0782608695652174, 0.02631578947368421, 0.008849557522123894, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 6.388888888888889, 'translation_length': 115, 'reference_length': 18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 50%|█████     | 2/4 [00:13<00:13,  6.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In comparison to our application, which music streaming platform are users most likely to compare ours with?\n",
      "\n",
      "    Based on the given context, it seems that users are most likely to compare Spotify with other popular music streaming platforms such as Apple Music, Tidal, and Amazon Music. However, the specific comparisons may vary depending on the user's personal preferences and experiences with these platforms.\n",
      "{'bleu': 0.0, 'precisions': [0.07692307692307693, 0.0, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 3.7142857142857144, 'translation_length': 52, 'reference_length': 14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      " 75%|███████▌  | 3/4 [00:25<00:08,  8.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the primary reasons users express dissatisfaction with Spotify?\n",
      "\n",
      "    ### ANSWER:\n",
      "    Based on the given context, some primary reasons users express dissatisfaction with Spotify include:\n",
      "\n",
      "    1. Unhelpful suggested songs: Some users become angry when suggested songs are vastly different from their selected genre, damaging the reputation of suggested artists and causing them to actively avoid listening to them.\n",
      "    2. Poor customer service: Users complain about abysmal customer service, with Spotify seemingly unable to resolve even basic technical issues and failing to address issues reported by multiple users over long periods of time.\n",
      "    3. Annoying ads and forced upgrades: Users criticize Spotify for adding too many ads and forcing users to upgrade to premium to turn off limits on collections or remove unwanted songs added by Spotify itself.\n",
      "    4. Slow updates and unnecessary features: Users dislike slow updates and unnecessary features, such as flashy animations, and suggest simplifying the software and making it faster.\n",
      "    5. Design flaws and lack of incentives: Some users find the design of Spotify lacking and prefer other products with better incentives.\n",
      "    6. Technical issues: Users report technical issues, such as songs disappearing from their library or becoming unavailable for download\n",
      "{'bleu': 0.0, 'precisions': [0.03773584905660377, 0.009478672985781991, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 8.153846153846153, 'translation_length': 212, 'reference_length': 26}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py:331: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='note 8 is a bug factory. pandora is blowing zuckerberg. spotify has not shined. play a list and only one song at a time plays. help is a joke. download limit on a paid account was hit on the second day. pointless family plan for modern families. bout eqaul with its competition. postmodern spectacle of a complete product with zero realistic qc.', metadata={'review_id': 'c7c74a02-8565-482a-9c9a-79bbd96890a2', 'pseudo_author_id': '281305978879399275572'}), -0.03573191165924072), (Document(page_content='getting alot more commerical than before', metadata={'review_id': 'a5db976c-65f0-40fe-8f84-bdda232a1947', 'pseudo_author_id': '174544560616810006389'}), -0.06935703754425049), (Document(page_content='consistent bad ui design decisions that make the service increasingly less enjoyable to use.', metadata={'review_id': 'dca5b3ab-8bfe-472b-bbaa-f50aa7396db5', 'pseudo_author_id': '227941293633078062138'}), -0.0992579460144043), (Document(page_content=\"hmm.. i have just a couple suggestions but i'll hold it off until a few more updates.. so far it's moderate..\", metadata={'review_id': 'ca490b9e-10ff-43b3-82de-450b8997a16d', 'pseudo_author_id': '217802634080404435378'}), -0.11610400676727295), (Document(page_content=\"3 month updated review gifs in the background instead of album covers are disableable. there's a lot one can do in the settings.  songsalbums sorted by popularity instead of release dates still exists.  also don't expect artist updates unless it's about a popular artist.  album covers aren't always expandable.  year in review stats are great.  voice command on phones and other devices seems to work fairly well.  but it doesn't recognize user playlists by voice command.\", metadata={'review_id': 'fa3d88f7-2df9-45af-93bf-46d589038977', 'pseudo_author_id': '208037739407139706613'}), -0.11766469478607178), (Document(page_content=\"infrequent feature updates ignored user base complaints broken integration vague quality settings stupid default settings generally a low effort company with poor standards coasting on name recognition and failing to uphold the interests of it's users.\", metadata={'review_id': '8f945c7e-4876-4594-a7c2-a8493351d034', 'pseudo_author_id': '338541981206502366960'}), -0.12958741188049316), (Document(page_content=\"utilizing more and more complicated algorithms to make people pay for subscription. you literally almost cannot do anything anymore unless you pay what wasn't the case when we all made our opinion before\", metadata={'review_id': '5d26869c-7ea5-4aa6-a2fe-e4eafa577c16', 'pseudo_author_id': '133125327907419306414'}), -0.13114690780639648), (Document(page_content=\"slowly updating suggestions slowly getting better. an actual change log would be nice but they clearly don't have a social media employee\", metadata={'review_id': '0b5e8c0a-14ba-4bb6-9f43-f15e93b8c3e5', 'pseudo_author_id': '157692317722850984078'}), -0.1355597972869873), (Document(page_content=\"my biggest gripe is the lack of a dislikedownvote button. i read on your forums that you won't give us one is because it feels too negative but how else are your algorithms to know that when i ask my speaker to play goddess on a highway by mercury rev i don't want to hear an obscure 90s bootleg but the album version choice is important and personal preference is both negative and positive and your algorithms won't get smarter if you don't collect data on what people don't like as well.\", metadata={'review_id': '12a873b5-26f5-4501-82c7-80682947dd22', 'pseudo_author_id': '274954685574605190221'}), -0.15109598636627197), (Document(page_content='will continue to use instead of competitors', metadata={'review_id': '12b15603-ed25-44cb-acc1-f62ad219207c', 'pseudo_author_id': '122378239575451464411'}), -0.15217161178588867)]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py:343: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.2\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "100%|██████████| 4/4 [00:37<00:00,  9.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can you identify emerging trends or patterns in recent user reviews that may impact our product strategy?\n",
      "\n",
      "    Our application, Spotify, has received several user reviews in recent times. After analyzing these reviews, we have identified some emerging trends and patterns that could potentially impact our product strategy. Some of these trends include:\n",
      "\n",
      "1. Increased demand for personalized playlists: Many users have expressed their desire for more personalized playlists that cater to their specific tastes and preferences. This trend highlights the importance of investing in AI-powered algorithms that can analyze user listening habits and generate customized playlists.\n",
      "\n",
      "2. Growing preference for podcasts: The popularity of podcasts has been on the rise, with many users requesting more diverse and high-quality content. To meet this demand, we could consider expanding our podcast library and partnering with popular podcasters to offer exclusive content to our users.\n",
      "\n",
      "3. Need for better audio quality: Several users have complained about poor audio quality during streaming, which affects their overall listening experience. To address this issue, we could explore ways to improve audio quality, such as investing in better encoding technologies or collaborating with music labels to ensure higher quality recordings.\n",
      "\n",
      "4. Demand for offline listening: With the increasing use of mobile devices, many users prefer to listen to music off\n",
      "{'bleu': 0.0, 'precisions': [0.036036036036036036, 0.004524886877828055, 0.0, 0.0], 'brevity_penalty': 1.0, 'length_ratio': 9.652173913043478, 'translation_length': 222, 'reference_length': 23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import faithfulness, answer_relevancy, context_recall, context_precision\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "\n",
    "bleu = evaluate.load('bleu')\n",
    "# perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "\n",
    "question = benchmark_df[\"questions\"].tolist()\n",
    "questions, answers, contexts, ground_truth, scores_bleu, scores_ppxy = [], [], [], [], [], []\n",
    "for i,q in enumerate(tqdm(question)):\n",
    "    answer, relevant_docs = answer_with_rag(q, llm_chain, db, k_retrieve=10)\n",
    "    score_bleu = bleu.compute(predictions=[answer], references=[benchmark_df[\"answers\"][i]])\n",
    "    # score_ppxy = perplexity.compute(model_id='mistralai/Mistral-7B-Instruct-v0.1',\n",
    "    #                          add_start_token=False,\n",
    "    #                          predictions=answer)\n",
    "    print(q)\n",
    "    print(answer)\n",
    "    print(score_bleu)\n",
    "    \n",
    "    questions.append(q)\n",
    "    answers.append(answer)\n",
    "    contexts.append(relevant_docs)\n",
    "    ground_truth.append(benchmark_df[\"answers\"][i])\n",
    "    scores_bleu.append(score_bleu)\n",
    "\n",
    "data = {\n",
    "    \"question\": questions,\n",
    "    \"answer\": answers,\n",
    "    \"contexts\": contexts,\n",
    "    \"ground_truth\": ground_truth,\n",
    "    \"scores_bleu\": scores_bleu\n",
    "}\n",
    "\n",
    "res_df = pd.DataFrame(data)\n",
    "# eval_df = evaluate_with_ragas(data)\n",
    "# eval_df.to_csv(\"eval_{}_{}.csv\".format(\"mistral\", \"benchmark\"),\n",
    "#                 index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ed3b3f95-e171-4cbb-98ba-f14a8eec7c72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Based on the provided documents, it appears that users may compare Spotify with other popular music streaming platforms such as Apple Music, Tidal, Amazon Music, Google Play Music, Deezer, Pandora, and SoundCloud. However, it's important to note that these comparisons may vary depending on individual preferences and needs.\n"
     ]
    }
   ],
   "source": [
    "question = \"In comparison to our application, which music streaming platform are users most likely to compare ours with?\"\n",
    "answer, relevant_docs = answer_with_rag(question, llm_chain, db, k_retrieve=20)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a9bb57e7-7597-4823-a81e-edbf205c9095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['awesome comparing other music app competitors', 'preferred streaming music app', 'my preferred online streaming music app', 'best music platform.', 'best music platform', 'best music platform', 'my preferred platform to stream all my favorite music', 'best streaming music platform', 'best music service.. best app and user experience across different devices and different operating systems', 'best music streaming app no comparison to the plethora of music content']\n"
     ]
    }
   ],
   "source": [
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "beb40a22-2c26-436b-a53d-caa791001892",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Based on the provided documents, some of the specific features or aspects that users appreciate the most in the Spotify application include:\n",
      "\n",
      "    - Ease of use and intuitive interface\n",
      "    - A wide variety of music options and genres available\n",
      "    - Social features such as sharing music and connecting with friends\n",
      "    - Quick and helpful customer support\n",
      "    - Personalized recommendations based on user preferences\n",
      "    - The ability to create and share playlists\n",
      "    - Integration with other devices and services\n",
      "    - Convenient and efficient features such as offline listening and streaming quality.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the specific features or aspects that users appreciate the most in our application?\"\n",
    "answer, relevant_docs = answer_with_rag(question, llm_chain, db, k_retrieve=10)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b3f77b7-d0d7-41bc-b2c4-4a9c6f47f9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the most important app attributes  it works', 'ease of use i am technology apps and really anything having to do with new stuff.. but i was able to navigate this app pretty well straight away. i am sure there are a lot more features available but for being a novice i am using this app fine', 'for me it is amazing apps..', 'good social skills and very quick to help and fix any problems i have. love this app', 'ease of use and intuitive interface. all the new hits found on this app. great piece.', 'i like that sootify does things for the customer. and that you can help others through this app. also i can listen to absolutely anything any mood or genre the music to satisfy is on this app', 'enjoy this app quite a bit. bit there is only one thing that would make this app outstanding.', 'an app that is efficient convenient and absolutely tonefriendly when it comes to what a customer wants.']\n"
     ]
    }
   ],
   "source": [
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "413645e0-7a73-4383-9838-243632bd3e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The primary reasons users express dissatisfaction with Spotify include:\n",
      "\n",
      "1. Poor customer service: Users have reported difficulty resolving technical issues and have expressed frustration with the lack of a phone number to call for support.\n",
      "2. Advertising: Some users have expressed annoyance with the amount of advertising on the platform, as well as the fact that Spotify adds its own songs to their playlists without their consent.\n",
      "3. Limited customization options: Users have requested more control over their collections and playlists, including the ability to turn off certain features and remove flashy animations from the app.\n",
      "4. Slow performance and functionality issues: Some users have reported that updates to the software have made it slower and less functional, and have called for improvements in these areas.\n",
      "5. Lack of messaging features: Users have expressed disappointment that Spotify no longer allows them to message friends through the app, and have suggested bringing this feature back.\n",
      "6. Inadequate incentives: Some users have compared Spotify unfavorably to other products and have expressed dissatisfaction with the incentives offered by the platform.\n",
      "7. Design and user experience: Users have criticized the design of the app and have called for a simpler\n"
     ]
    }
   ],
   "source": [
    "question = \"What are the primary reasons users express dissatisfaction with Spotify?\"\n",
    "answer, relevant_docs = answer_with_rag(question, llm_chain, db, k_retrieve=10)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3ec03d4-d18f-456b-8e58-4c4df6c02a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"a thousand curses on your suggested songs. listening to music is an emotional experience. when a suggested song comes up that is completely different from my selected genre i feel angry. anger towards spotify because it has now damaged those suggested artists who's first impression is negative and i will actively avoid listening to. remember that free u2 album on itunes thing it's like that.\", \"abysmal customer service they seem incapable of resolving even some of the most basic technical issues and they don't even have a number to call. just browse their forums for technical issues and you'll find pages and pages spanning years of customers with unsolved issues and spotify never fixing an issue that so many users are all reporting to have. when everything works smoothly it's great. but accidentally linked your account to someone else's psn account and now you want to link it to your\", 'too much ad and spotify songs. spotify was good until they have added too much of advertising. also they add their own songs in my playlist which is not related to i am playing and became very annoying. after reading found that that feature can be turned off only if i upgrade to premium. it is like putting a gun on someone head and say do this or we will do that. spotify making enough by advertising bunch of stuff which is not related what i do or use then why force by playing annoying song.', 'pathetic customer support from a company that owns such a large  of the streaming market. nearly every update makes the software slowerless functional. get rid of limits on collections imagine paying premium to have limits on your library stop adding flashy animations to the app make it simple and faster. bring back messaging to other friends. i might switch to tidal because spotify do not care about providing any customer service.', \"i just didn't care for spotify. it never fulfilled its promise. the design could be cleaner and in terms of incentives it doesn't hold a candle to other products.\", 'incredible what is there to not like about spotify', 'i love spotify so much why are you people complaining', 'very dissatisfied with spotify', 'what is there to not love spotify', \"same complaint as everyone recently have been using spotify for years and liked the layout had a few issues with casting to tv my songs randomly going missingbecoming not downloaded etc that i can get over but the new interface is horrible so i'm seriously looking at other providers now.\"]\n"
     ]
    }
   ],
   "source": [
    "print(relevant_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a70eba5-6431-4eff-8225-857ccd0031c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py:331: UserWarning: Relevance scores must be between 0 and 1, got [(Document(page_content='note 8 is a bug factory. pandora is blowing zuckerberg. spotify has not shined. play a list and only one song at a time plays. help is a joke. download limit on a paid account was hit on the second day. pointless family plan for modern families. bout eqaul with its competition. postmodern spectacle of a complete product with zero realistic qc.', metadata={'review_id': 'c7c74a02-8565-482a-9c9a-79bbd96890a2', 'pseudo_author_id': '281305978879399275572'}), -0.03573191165924072), (Document(page_content='getting alot more commerical than before', metadata={'review_id': 'a5db976c-65f0-40fe-8f84-bdda232a1947', 'pseudo_author_id': '174544560616810006389'}), -0.06935703754425049), (Document(page_content='consistent bad ui design decisions that make the service increasingly less enjoyable to use.', metadata={'review_id': 'dca5b3ab-8bfe-472b-bbaa-f50aa7396db5', 'pseudo_author_id': '227941293633078062138'}), -0.0992579460144043), (Document(page_content=\"hmm.. i have just a couple suggestions but i'll hold it off until a few more updates.. so far it's moderate..\", metadata={'review_id': 'ca490b9e-10ff-43b3-82de-450b8997a16d', 'pseudo_author_id': '217802634080404435378'}), -0.11610400676727295), (Document(page_content=\"3 month updated review gifs in the background instead of album covers are disableable. there's a lot one can do in the settings.  songsalbums sorted by popularity instead of release dates still exists.  also don't expect artist updates unless it's about a popular artist.  album covers aren't always expandable.  year in review stats are great.  voice command on phones and other devices seems to work fairly well.  but it doesn't recognize user playlists by voice command.\", metadata={'review_id': 'fa3d88f7-2df9-45af-93bf-46d589038977', 'pseudo_author_id': '208037739407139706613'}), -0.11766469478607178), (Document(page_content=\"infrequent feature updates ignored user base complaints broken integration vague quality settings stupid default settings generally a low effort company with poor standards coasting on name recognition and failing to uphold the interests of it's users.\", metadata={'review_id': '8f945c7e-4876-4594-a7c2-a8493351d034', 'pseudo_author_id': '338541981206502366960'}), -0.12958741188049316), (Document(page_content=\"utilizing more and more complicated algorithms to make people pay for subscription. you literally almost cannot do anything anymore unless you pay what wasn't the case when we all made our opinion before\", metadata={'review_id': '5d26869c-7ea5-4aa6-a2fe-e4eafa577c16', 'pseudo_author_id': '133125327907419306414'}), -0.13114690780639648), (Document(page_content=\"slowly updating suggestions slowly getting better. an actual change log would be nice but they clearly don't have a social media employee\", metadata={'review_id': '0b5e8c0a-14ba-4bb6-9f43-f15e93b8c3e5', 'pseudo_author_id': '157692317722850984078'}), -0.1355597972869873), (Document(page_content=\"my biggest gripe is the lack of a dislikedownvote button. i read on your forums that you won't give us one is because it feels too negative but how else are your algorithms to know that when i ask my speaker to play goddess on a highway by mercury rev i don't want to hear an obscure 90s bootleg but the album version choice is important and personal preference is both negative and positive and your algorithms won't get smarter if you don't collect data on what people don't like as well.\", metadata={'review_id': '12a873b5-26f5-4501-82c7-80682947dd22', 'pseudo_author_id': '274954685574605190221'}), -0.15109598636627197), (Document(page_content='will continue to use instead of competitors', metadata={'review_id': '12b15603-ed25-44cb-acc1-f62ad219207c', 'pseudo_author_id': '122378239575451464411'}), -0.15217161178588867)]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/langchain_core/vectorstores.py:343: UserWarning: No relevant docs were retrieved using the relevance score threshold 0.2\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:410: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.1` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Based on recent user reviews of Spotify, some emerging trends and patterns that may impact our product strategy include:\n",
      "\n",
      "1. Increased demand for personalized recommendations: Many users have expressed frustration with the lack of personalized recommendations provided by Spotify. They want more tailored playlists and recommendations based on their listening habits and preferences. This suggests that we should focus on improving our recommendation algorithms and incorporating more data about each user's listening behavior.\n",
      "2. Growing interest in podcasts: While music remains a popular content category on Spotify, there has been a significant increase in the number of users who are also interested in podcasts. This trend suggests that we should continue to invest in podcast content and improve our podcast discovery and recommendation features.\n",
      "3. Concerns about ad interruptions: Some users have expressed frustration with the frequency and duration of ads on Spotify. They want more control over when and how they see ads, and some have suggested that we consider offering premium ad-free options. This suggests that we should explore ways to balance our advertising revenue with user experience and satisfaction.\n",
      "4. Demand for social features: Many users have requested additional social features on Spotify, such as the ability to share playlists\n"
     ]
    }
   ],
   "source": [
    "question = \"Can you identify emerging trends or patterns in recent user reviews that may impact our product strategy?\"\n",
    "answer, relevant_docs = answer_with_rag(question, llm_chain, db, k_retrieve=10)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf488e0-2a80-416a-ab05-e6616cdd59d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
